{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKWvMXWMBEJA"
   },
   "source": [
    "# Behavioural Planning for Autonomous Highway Driving\n",
    "\n",
    "We plan a trajectory using the _Optimistic Planning for Deterministic systems_ ([OPD](https://hal.inria.fr/hal-00830182)) algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS THE RESET!\n",
      "{'observation': {'type': 'Kinematics'}, 'action': {'type': 'DiscreteMetaAction'}, 'simulation_frequency': 15, 'policy_frequency': 1, 'other_vehicles_type': 'highway_env.vehicle.behavior.IDMVehicle', 'screen_width': 600, 'screen_height': 150, 'centering_position': [0.3, 0.5], 'scaling': 5.5, 'show_trajectories': False, 'render_agent': True, 'offscreen_rendering': False, 'manual_control': False, 'real_time_rendering': False, 'lanes_count': 6, 'vehicles_count': 1, 'controlled_vehicles': 1, 'initial_lane_id': None, 'duration': 60, 'ego_spacing': 2, 'vehicles_density': 1, 'collision_reward': -1, 'right_lane_reward': 0.1, 'high_speed_reward': 0.4, 'lane_change_reward': 0, 'reward_speed_range': [20, 30], 'normalize_reward': True, 'offroad_terminal': False}\n",
      "THIS IS THE RESET!\n",
      "[[ 1.          1.          0.3579927   0.31180274 -0.02086364]\n",
      " [ 1.          0.06647895 -0.02465937 -0.0443819   0.02086364]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "{'speed': 25.0, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.4, 'high_speed_reward': 0.4944220488427259, 'on_road_reward': 1.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:42: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (5, 5)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          0.33572203  0.26067272 -0.00201617]\n",
      " [ 1.          0.06105385 -0.00238869  0.00674814  0.00201617]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "{'speed': 20.8544411731307, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.4, 'high_speed_reward': 0.08538174186600571, 'on_road_reward': 1.0}}\n",
      "[[ 1.0000000e+00  1.0000000e+00  3.3357471e-01  2.5182509e-01\n",
      "  -2.0856228e-04]\n",
      " [ 1.0000000e+00  6.5897360e-02 -2.4139194e-04  1.5595766e-02\n",
      "   2.0856228e-04]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00]]\n",
      "{'speed': 20.146013943668194, 'crashed': False, 'action': 4, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.4, 'high_speed_reward': 0.014600703439359108, 'on_road_reward': 1.0}}\n",
      "[[ 1.          1.          0.19247094  0.24943432 -0.02094202]\n",
      " [ 1.          0.07411896  0.14086239  0.01798653  0.02094202]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "{'speed': 20.024952065064255, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.2, 'high_speed_reward': 0.0, 'on_road_reward': 1.0}}\n",
      "[[ 1.          1.          0.02841749  0.24897133 -0.02323639]\n",
      " [ 1.          0.08327121  0.30491585  0.01844952  0.02323639]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "{'speed': 20.004264014349108, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.0, 'high_speed_reward': 0.0, 'on_road_reward': 1.0}}\n",
      "[[ 1.          1.          0.14385481  0.24933405  0.01835996]\n",
      " [ 1.          0.09128986  0.18947852  0.01808681 -0.01835996]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "{'speed': 20.00072866988454, 'crashed': False, 'action': 2, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.2, 'high_speed_reward': 0.0, 'on_road_reward': 1.0}}\n",
      "[[ 1.          1.          0.02336974  0.24928999 -0.01884891]\n",
      " [ 1.         -0.04245642  0.14329693  0.06321002  0.01884891]\n",
      " [ 1.          0.09941768  0.30996358  0.01813087  0.01884891]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "{'speed': 20.000124521110198, 'crashed': False, 'action': 0, 'rewards': {'collision_reward': 0.0, 'right_lane_reward': 0.0, 'high_speed_reward': 0.0, 'on_road_reward': 1.0}}\n",
      "[[ 1.          1.          0.15267868  0.17535941  0.02449361]\n",
      " [ 1.         -0.02557149  0.01398798  0.04596734 -0.02449361]\n",
      " [ 1.          0.10765564  0.18065464  0.09206145 -0.02449361]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n",
      "{'speed': 14.164939092397683, 'crashed': True, 'action': 2, 'rewards': {'collision_reward': 1.0, 'right_lane_reward': 0.2, 'high_speed_reward': 0.0, 'on_road_reward': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make('highway-v0', render_mode='rgb_array')\n",
    "print(env.config)\n",
    "obs, info = env.reset()\n",
    "done = truncated = False\n",
    "while not (done):\n",
    "   action = env.action_space.sample()\n",
    "   obs, reward, done, truncated, info = env.step(action)\n",
    "   print(obs)\n",
    "   print(info)\n",
    "   obs = env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-ghXis6A_md"
   },
   "outputs": [],
   "source": [
    "#@title Imports for env, agent, and visualisation.\n",
    "# Environment\n",
    "!pip install highway-env\n",
    "import gymnasium as gym\n",
    "import highway_env\n",
    "\n",
    "# Agent\n",
    "!pip install git+https://github.com/eleurent/rl-agents#egg=rl-agents\n",
    "from rl_agents.agents.common.factory import agent_factory\n",
    "\n",
    "# Visualisation\n",
    "import sys\n",
    "from tqdm.notebook import trange\n",
    "!pip install moviepy -U\n",
    "!pip install imageio_ffmpeg\n",
    "!pip install pyvirtualdisplay\n",
    "!apt-get install -y xvfb python-opengl ffmpeg\n",
    "!git clone https://github.com/eleurent/highway-env.git\n",
    "sys.path.insert(0, './highway-env/scripts/')\n",
    "from utils import record_videos, show_videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgNDDWwqCj8l"
   },
   "outputs": [],
   "source": [
    "#@title Run an episode\n",
    "\n",
    "# Make environment\n",
    "env = gym.make(\"highway-fast-v0\", render_mode=\"rgb_array\")\n",
    "env = record_videos(env)\n",
    "(obs, info), done = env.reset(), False\n",
    "\n",
    "# Make agent\n",
    "agent_config = {\n",
    "    \"__class__\": \"<class 'rl_agents.agents.tree_search.deterministic.DeterministicPlannerAgent'>\",\n",
    "    \"env_preprocessors\": [{\"method\":\"simplify\"}],\n",
    "    \"budget\": 50,\n",
    "    \"gamma\": 0.7,\n",
    "}\n",
    "agent = agent_factory(env, agent_config)\n",
    "\n",
    "# Run episode\n",
    "for step in trange(env.unwrapped.config[\"duration\"], desc=\"Running...\"):\n",
    "    action = agent.act(obs)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "env.close()\n",
    "show_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "highway-planning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
